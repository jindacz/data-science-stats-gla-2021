}
gen.gamma=function(n,mu,sigma){ #gen.gamma
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
x
gen.gamma.once=function(n,mu,sigma){ #auxiliary function
x=numeric(n)
a=mu^2/sigma^2 #1
b=mu/sigma^2
lambda=b/a #2
x.star=a/b
c=f(x.star,a,b)/g(x.star,lambda) #3
while(TRUE){
y=rexp(1, rate = lambda) #4.1
u=runif(1) #4.2
alpha=f(y,a,b)/(c*g(y,lambda)) #4.3
if(u<alpha) break
}
x=y #4.4
}
gen.gamma=function(n,mu,sigma){ #gen.gamma
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
x
#d
x=gen.gamma.once(1000,47,26)
x
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
x
x
#d
x=gen.gamma(1000,47,26)
x
#d
x=gen.gamma(1000,47,26)
x
for(i in 1:1000){
x[i]=gen.gamma.once(1000,mu,sigma)
}
for(i in 1:1000){
x[i]=gen.gamma(1000,47,26)
}
x
#d
x=gen.gamma(1000,47,26)
x
#10
#a
f=function(x,a,b){
(b^a)*(gamma(a))^(-1)*x^(a-1)*exp(-b*x)
}
#b
g=function(x,lambda){
lambda*exp(-lambda*x)
}
gen.gamma.once=function(n,mu,sigma){ #auxiliary function
x=numeric(n)
a=mu^2/sigma^2 #1
b=mu/sigma^2
lambda=b/a #2
x.star=a/b
c=f(x.star,a,b)/g(x.star,lambda) #3
while(TRUE){
y=rexp(1, rate = lambda) #4.1
u=runif(1) #4.2
alpha=f(y,a,b)/(c*g(y,lambda)) #4.3
if(u<alpha) break
}
x=y #4.4
}
#d
x=gen.gamma.once(1000,47,26)
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
x
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
ntimes=n
for(i in 1:ntimes){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
ntimes=n
for(i in 1:ntimes){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
#succeed
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
#or
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
x
hist(x,freq=F)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
k=n
for(k in 1:k){
x[k]=gen.gamma.once(n,mu,sigma)
}
}
x=gen.gamma(1000,47,26)
View(g)
f=function(x,a,b){
(b^a)*(gamma(a))^(-1)*x^(a-1)*exp(-b*x)
}
#b
g=function(x,lambda){
lambda*exp(-lambda*x)
}
x=numeric(100000)
gen.gamma=function(n,mu,sigma){ #gen.gamma
k=n
for(k in 1:k){
x[k]=gen.gamma.once(n,mu,sigma)
}
}
x=gen.gamma(1000,47,26)
x=numeric(100000)
gen.gamma=function(n,mu,sigma){ #gen.gamma
replicate(n,gen.gamma(n,mu,sigma))
}
x=replicate(100,gen.gamma(n,mu,sigma))
x=replicate(100,gen.gamma(1000,47,26))
x=replicate(3,gen.gamma(1000,47,26))
a
1
A
A=cbind(c(1,1),c(1,-1))
A
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(ggplot2)
library(nycflights13)
print("Well done!  You've loaded the libraries")
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
nycflights13
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(ggplot2)
1
library(nycflights13)
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
#das_lab_1
install.packages("ggplot2") #Only include if the package hasn't already been installed
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(R2OpenBUGS)
model{{
model{{
theta~dunif(0,1)
}
model{
theta~dunif(0,1)
}
model{theta~dunif(0,1)}
#HW2_problem 4
nsamp=100000
theta=rbeta(nsamp,17,5)
mean(theta>0.5&theta<0.7)
mean(theta)
quantile(theta,probs=c(0.025,0.975))  # 95% central posterior
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
print("Well done!  You've loaded the libraries")
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(nycflights13)
library(nycflights13)
install.packages("nycflights13") #Only include if the package hasn't already been installed
#######################
#Calculating new scores
#######################
new.data<-data.frame(log.length=c(4.8),log.width=c(4.7),log.breadth=c(3.9))
predict(pca.turt.new,new.data)
#W1_example_1+task_6
wine=read.csv("wine.data.csv")
#mining_week_1
#Task_8
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/mining/Datasets\ for\ week\ 1")
#####################
#W1_example_1+task_6
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/mining/Datasets\ for\ week\ 1")
wine=read.csv("wine.data.csv")
str(wine,vec.len=2)
summary(wine)
library(skimr)
skim(wine)
# If you want specific columns to disappear from the output, you set them to
# NULL as follows
my_skim=skim_with(base=sfl(n=length),numeric=sfl(p0=NULL,p100=NULL,
hist=NULL))
my_skim(wine)
library(knitr)
knit_print(my_skim(wine))
pairs(wine[,c(1:2,5:8,14)],pch=20,lower.panel=NULL)
#It’s a little hard to see anything clearly but we can see that the first variable is not continuous (it only
#takes three values). We can also see potential outliers in a couple of scatterplots e.g. lower right corner of
#Flavanoids and Proline plot. There is evidence of some strong linear relationships between some pairs of
#variables, e.g. Total phenols and Flavanoids in particular. We can use the base command plot AND the
#identify command to look at the Flanavoids and Proline graph and identify the outlier (on the far right).
plot(wine$Flavanoids,wine$Proanthocyanins,xlab="Flanavoids",ylab="Proline")
#Use the mouse to click on the point you want and the Esc key to stop the command
outlier=identify(cbind(wine$Flavanoids,wine$Proline))
#We can now remove the outlier (i.e. the 122th observation) and the first variable (i.e. Class) from our
#dataset and look at a correlation matrix.
wine.new=wine[-122,-1]
install.packages("corrplot")
library(corrplot)
M=cor(wine.new)
corrplot(M,method="number",type="upper")
11
1
1
#Well, looking at the variances we can see huge differences between the variables (e.g. Ash and Proline,
#etc) which strongly suggests we use the correlation matrix.
wine.pca=princomp(wine.new,cor=T)
wine.pca
summary(wine.pca)
#Cattell’s method
plot(wine.pca)
#Kaiser’s method: Here we need to look at finding the average eigenvalue to discover which set of components have variation above it that we will retain. Because we used the correlation matrix, we know the
#average should be 1 but let’s check.
#extract the component standard deviations
sd.pca=wine.pca$sdev
sd.pca
#find the average var,take the mean after squaring them
ave.var=mean((sd.pca^2))
#find the average var,take the mean after squaring them
ave.var=mean((sd.pca^2))
ave.var
#Find which components have higher than average variance (TRUE)
sd.pca^2>ave.var
#task 3
wine.pca$sdev^2
#example_3
#loadings
wine.pca$loadings[,1:8]
#We are usually interested in examining what the data look like in the new reduced space. The scores for
#the PCs on the original data are automatically produced by princomp. So we can look at the pairs plot of
#the 3 PCs we decided to retain.
scores.wine=wine.pca$scores[,1:3]
scores.wine
pairs(scores.wine,pch=20,lower.panel=NULL)
#task_5
#by hand using R as a calculator
new.x=matrix(c(12,4,3,25,100,2,1,0.4,2,4,1,2,600),nrow=1)
colnames(new.x)=colnames(wine.new)
centre.wine=wine.pca$centre
scale.wine=wine.pca$scale
first.load=wine.pca$loadings[,1]
#task_5
#by hand using R as a calculator
new.x=matrix(c(12,4,3,25,100,2,1,0.4,2,4,1,2,600),nrow=1)
colnames(new.x)=colnames(wine.new)
centre.wine=wine.pca$centre
scale.wine=wine.pca$scale
first.load=wine.pca$loadings[,1]
new.x.cent=new.x-centre.wine
new.x.stand=new.x.cent/scale.wine
new.x.stand%*%first.load
new.x.cent<-new.x-centre.wine
new.x.stand<-new.x.cent/scale.wine
new.x.stand%*%first.load
#task_5
#By hand using R as a calculator
new.x<-matrix(c(12,4,3,25,100,2,1,0.4,2,4,1,2,600),nrow=1)
colnames(new.x)<-colnames(wine.new)
centre.wine<-wine.pca$center
scale.wine<-wine.pca$scale
first.load<-wine.pca$loadings[,1]
new.x.cent<-new.x-centre.wine
new.x.stand<-new.x.cent/scale.wine
new.x.stand%*%first.load
#use the predict command
predict(wine.pca,as.data.frame(new.x))
employ=read.table("eurojob.txt",header=T,row.names=1)
#example_5
employ=read.table("eurojob.txt",header=T,row.names=1);head(employ,4)
#task_6
#Let’s start exploring the data by producing some numerical summaries.
summary(employ)
knit_print(my_skim(employ))
#Look at pairs plots for the data
pairs(employ,pch=20,lower.panel.NULL)
#Look at pairs plots for the data
pairs(employ,pch=20,lower.panel=NULL)
library(matrixcalc)
#Display the correlation matrix to 2 d.p.s
#library(matrixcalc)
install.packages("matrixcalc")
#Display the correlation matrix to 2 d.p.s
#library(matrixcalc)
install.packages("matrixcalc")
library(matrixcalc)
#Display the correlation matrix to 2 d.p.s
#library(matrixcalc)
install.packages("matrixcalc")
library(matrixcalc)
round(cor(employ),2)
#Look at the standard deviations of the variables
round(sqrt(diag(cov(employ))),1)
#We can use the princomp command to implement PCA
employ.pca=princomp(employ,cor=T)
employ.pca
#The summary function can give us information about how many components we should keep.
summary(employ.pca)
#For Cattell’s method we will need to produce a scree plot.
plot(employ.pca)
#For Kaiser’s method we need to look at finding the average eigenvalue to discover which set of components have
#variation above it that we will retain.
employ.pca$sdev^2>1
#Let’s now have a look at the loadings from each component.
employ.pca$loadings
#Let’s now have a look at the loadings from each component.
employ.pca$loadings
employ.pca$loadings
#The summary function can give us information about how many components we should keep.
summary(employ.pca)
###For Cattell’s method we will need to produce a scree plot.
plot(employ.pca)
#5.Assuming we are most concerned with preserving information, how many coefficients should we
#retain if we want to have 90% of the original variability kept?
summary(employ.pca)
colnames(newdata)=colnames(employ)
#task_7
#we can calculate the scores using the following code
obs1<-c(5.1,0.5,32.3,0.8,8.1,16.7,4.3,21.2,6.3)
obs2<-c(4.2,0.7,25.4,0.7,9.3,15.0,5.8,31.0,6.9)
newdata=rbind(obs1,obs2)
colnames(newdata)=colnames(employ)
new.data.scores=predict(employ.pca,new.data)
#task_7
#we can calculate the scores using the following code
obs1<-c(5.1,0.5,32.3,0.8,8.1,16.7,4.3,21.2,6.3)
obs2<-c(4.2,0.7,25.4,0.7,9.3,15.0,5.8,31.0,6.9)
newdata=rbind(obs1,obs2)
colnames(newdata)=colnames(employ)
new.data.scores=predict(employ.pca,new.data)
newdata<-rbind(obs1,obs2);colnames(newdata)<-colnames(employ)
new.data<-as.data.frame(newdata);
new.data.scores<-predict(employ.pca,new.data)
new.data.scores[, 1:6]
new.data.scores[, 1:7]
new.data.scores[, 1:6]
#Let’s produce the scatterplot first
employ.scores2=as.data.frame(employ.pca$scores[,1:2])
#Let’s produce the scatterplot first
employ.scores2=as.data.frame(employ.pca$scores[,1:2])
plot(employ.scores2$Comp.1,employ.scores2$Comp.2,xlab="Comp.1", ylab="Comp.2")
#task_8 use prcomp instead of princomp
#Setting the random generator seed to ensure similar responses when re-running code
set.seed(135)
#############################
#Principal Component Analysis
#############################
pca.turt.2<-prcomp(log.fem.turt[-10,]);pca.turt.2
####################################
#Deciding on number of PCs to retain
####################################
plot(pca.turt.2);summary(pca.turt.2)
sd.pca<-summary(pca.turt.2)$sdev
####################################
#Deciding on number of PCs to retain
####################################
plot(pca.turt.2);summary(pca.turt.2)
sd.pca<-summary(pca.turt.2)$sdev
tot.var<-sum(sd.pca^2)
ave.var<-tot.var/ncol(log.fem.turt)
ave.var
28
ave.var
sd.pca^2>ave.var
#####################################################
#Interpreting the loadings and calculating new scores
#####################################################
pca.turt.2$rotation #loading matrix
# pca.turt.2$x #PC scores
new.data<-data.frame(log.length=c(4.8),log.width=c(4.7),log.breadth=c(3.9))
predict(pca.turt.2,new.data)
#####################################################
#Interpreting the loadings and calculating new scores
#####################################################
pca.turt.2$rotation #loading matrix
#############################
#Principal Component Analysis
#############################
pca.turt.2<-prcomp(log.fem.turt[-10,]);pca.turt.2
log.fem.turt
#das_week2
# tidyverse core packages
library(tidyverse)
# packages containing interesting data
library(nycflights13)
library(fivethirtyeight)
#das_week2
# tidyverse core packages
installed.packages("tidyverse","fivethirtyeight")
#das_week2
# tidyverse core packages
installed.packages("tidyverse")
#das_week2
# tidyverse core packages
installed.packages("tidyverse")
library(tidyverse)
#das_week2
# tidyverse core packages
installed.packages("tidyverse")
#das_week2
# tidyverse core packages
install.packages("tidyverse")
1
install.packages("fivethirtyeight")
library(fivethirtyeight)
# packages containing interesting data
library(nycflights13)
library(tidyverse)
#das_week2
# tidyverse core packages
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
#das_week2
# tidyverse core packages
install.packages("tidyverse")
library(tidyverse)
library(tidyverse)
install.packages("scales")
install.packages("scales")
library(tidyverse)
library(tidyverse)
install.packages("scales")
install.packages("scales")
#das_week2
# tidyverse core packages
install.packages("tidyverse")
library(tidyverse)
#das_week2
# tidyverse core packages
install.packages("tidyverse")
library(tidyverse)
install.packages("scales")
install.packages("broom", type="binary")
install.packages("broom", type = "binary")
library(tidyverse)
install.packages("pillar", type="binary")
install.packages("pillar", type = "binary")
library(tidyverse)
remove.packages("tidyverse")
#das_week2
# tidyverse core packages
install.packages("tidyverse")
library(tidyverse)
remove.packages("pillar")
remove.packages("tidyverse")
install.packages("pillar", type="binary")
install.packages("pillar", type = "binary")
#das_week2
# tidyverse core packages
install.packages("tidyverse")
library(tidyverse)
