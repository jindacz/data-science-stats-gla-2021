u=runif(1) #4.2
alpha=f(y,a,b)/(c*g(y,lambda)) #4.3
if(u<alpha) break
}
x=y #4.4
}
for(i in 1:1000){
x[i]=gen.gamma(1000,mu,sigma)
}
gen.gamma=function(n,mu,sigma){ #gen.gamma
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
x
gen.gamma.once=function(n,mu,sigma){ #auxiliary function
x=numeric(n)
a=mu^2/sigma^2 #1
b=mu/sigma^2
lambda=b/a #2
x.star=a/b
c=f(x.star,a,b)/g(x.star,lambda) #3
while(TRUE){
y=rexp(1, rate = lambda) #4.1
u=runif(1) #4.2
alpha=f(y,a,b)/(c*g(y,lambda)) #4.3
if(u<alpha) break
}
x=y #4.4
}
gen.gamma=function(n,mu,sigma){ #gen.gamma
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
x
#d
x=gen.gamma.once(1000,47,26)
x
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
x
x
#d
x=gen.gamma(1000,47,26)
x
#d
x=gen.gamma(1000,47,26)
x
for(i in 1:1000){
x[i]=gen.gamma.once(1000,mu,sigma)
}
for(i in 1:1000){
x[i]=gen.gamma(1000,47,26)
}
x
#d
x=gen.gamma(1000,47,26)
x
#10
#a
f=function(x,a,b){
(b^a)*(gamma(a))^(-1)*x^(a-1)*exp(-b*x)
}
#b
g=function(x,lambda){
lambda*exp(-lambda*x)
}
gen.gamma.once=function(n,mu,sigma){ #auxiliary function
x=numeric(n)
a=mu^2/sigma^2 #1
b=mu/sigma^2
lambda=b/a #2
x.star=a/b
c=f(x.star,a,b)/g(x.star,lambda) #3
while(TRUE){
y=rexp(1, rate = lambda) #4.1
u=runif(1) #4.2
alpha=f(y,a,b)/(c*g(y,lambda)) #4.3
if(u<alpha) break
}
x=y #4.4
}
#d
x=gen.gamma.once(1000,47,26)
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
x
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
for(i in 1:n){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
ntimes=n
for(i in 1:ntimes){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
ntimes=n
for(i in 1:ntimes){
x[i]=gen.gamma.once(n,mu,sigma)
}
}
#d
x=gen.gamma(1000,47,26)
#succeed
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
#or
for(i in 1:1000){
x[i]=gen.gamma.once(1000,47,26)
}
x
hist(x,freq=F)
gen.gamma=function(n,mu,sigma){ #gen.gamma
x=numeric(n)
k=n
for(k in 1:k){
x[k]=gen.gamma.once(n,mu,sigma)
}
}
x=gen.gamma(1000,47,26)
View(g)
f=function(x,a,b){
(b^a)*(gamma(a))^(-1)*x^(a-1)*exp(-b*x)
}
#b
g=function(x,lambda){
lambda*exp(-lambda*x)
}
x=numeric(100000)
gen.gamma=function(n,mu,sigma){ #gen.gamma
k=n
for(k in 1:k){
x[k]=gen.gamma.once(n,mu,sigma)
}
}
x=gen.gamma(1000,47,26)
x=numeric(100000)
gen.gamma=function(n,mu,sigma){ #gen.gamma
replicate(n,gen.gamma(n,mu,sigma))
}
x=replicate(100,gen.gamma(n,mu,sigma))
x=replicate(100,gen.gamma(1000,47,26))
x=replicate(3,gen.gamma(1000,47,26))
a
1
A
A=cbind(c(1,1),c(1,-1))
A
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(ggplot2)
library(nycflights13)
print("Well done!  You've loaded the libraries")
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
nycflights13
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(ggplot2)
1
library(nycflights13)
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
#das_lab_1
install.packages("ggplot2") #Only include if the package hasn't already been installed
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(R2OpenBUGS)
model{{
model{{
theta~dunif(0,1)
}
model{
theta~dunif(0,1)
}
model{theta~dunif(0,1)}
#HW2_problem 4
nsamp=100000
theta=rbeta(nsamp,17,5)
mean(theta>0.5&theta<0.7)
mean(theta)
quantile(theta,probs=c(0.025,0.975))  # 95% central posterior
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
1
library(ggplot2)
install.packages("nycflights13") #Only include if the package hasn't already been installed
print("Well done!  You've loaded the libraries")
install.packages("nycflights13") #Only include if the package hasn't already been installed
library(nycflights13)
library(nycflights13)
install.packages("nycflights13") #Only include if the package hasn't already been installed
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
model=lm(Hwt~Sex,data=cats)
#pdf subset
setwd("/Users/kurisuuu/Downloads")
#pdf subset
setwd("/Users/kurisuuu/Downloads")
pdf_subset('reg.pdf',pages = 26:87, output = "Geometric Unified Method in 3D Object Classification (1)")
library("pdftools")
#pdf subset
setwd("/Users/kurisuuu/Downloads")
pdf_subset('reg.pdf',pages = 26:87, output = "Geometric Unified Method in 3D Object Classification (1)")
pdf_subset('reg1.pdf',pages = 26:87, output = "Geometric Unified Method in 3D Object Classification (1)")
pdf_subset('reg1.pdf',pages = 26:87, output = "Geometric Unified Method in 3D Object Classification (1)")
pdf_subset('Geometric Unified Method in 3D Object Classification (1).pdf',pages = 26:87, output = "output.pdf")
library(dplyr)
library(ggplot2)
library(janitor)
library(moderndive)
library(dplyr)
library(ggplot2)
library(janitor)
library(moderndive)
library(infer)
library(broom)
slr.model=lm(score~age,data=evals)
coeff=slr.model%>%
coef()
coeff
bootstrap_beta_distn=evals%>%
specify(score~age)%>%
generate(reps=1000,type="bootstrap")%>%
calculate(stat="slope")
bootstrap_beta_distn%>%
visualize()
percentile_beta_ci <- bootstrap_beta_distn %>%
get_ci(level = 0.95, type = "percentile")
percentile_beta_ci
se_beta_ci <- bootstrap_beta_distn %>%
get_ci(level = 0.95, type = "se", point_estimate = coeff[2])
se_beta_ci
evals_multiple <- evals %>%
select(score, gender, age)
#让我们还回顾一下回归模型。一、无交互作用的回归模型：注意+公式中的使用。
par.model=lm(score~age+gender,data=evals_multiple)
get_regression_table(par.model)%>%
knitr::kable(
digits = 3,
caption = "Model 1: Regression model with no interaction effect included.",
booktabs = TRUE
)
int.model <- lm(score ~ age * gender, data = evals_multiple)
get_regression_table(int.model) %>%
knitr::kable(
digits = 3,
caption = "Model 2: Regression model with interaction effect included.",
booktabs = TRUE
)
#让我们还回顾一下回归模型。一、无交互作用的回归模型：注意+公式中的使用。
par.model=lm(score~age+gender,data=evals_multiple)
get_regression_table(par.model)%>%
knitr::kable(
digits = 3,
caption = "Model 1: Regression model with no interaction effect included.",
booktabs = TRUE
)
get_regression_table(int.model) %>%
knitr::kable(
digits = 3,
caption = "Model 2: Regression model with interaction effect included.",
booktabs = TRUE
)
get_regression_table(par.model)%>%
knitr::kable(
digits = 3,
caption = "Model 1: Regression model with no interaction effect included.",
booktabs = TRUE
)
get_regression_table(slr.model) %>%
knitr::kable(
digits = 3,
caption = "Estimates from the SLR model of `score` on `age`.",
booktabs = TRUE
)                                                                                                          让我们使用基于理论结果的置信区间，将 SLR 模型中的斜率参数应用于教师评价分数，age作为单一解释变量，教师评价scores 作为结果变量。
get_regression_table(slr.model) %>%
knitr::kable(
digits = 3,
caption = "Estimates from the SLR model of `score` on `age`.",
booktabs = TRUE
)                                                                                                          让我们使用基于理论结果的置信区间，将 SLR 模型中的斜率参数应用于教师评价分数，age作为单一解释变量，教师评价scores 作为结果变量。
get_regression_table(slr.model) %>%
knitr::kable(
digits = 3,
caption = "Estimates from the SLR model of `score` on `age`.",
booktabs = TRUE
)                                                                                                          让我们使用基于理论结果的置信区间，将 SLR 模型中的斜率参数应用于教师评价分数，age作为单一解释变量，教师评价scores 作为结果变量。
slr.model
get_regression_table(slr.model) %>%
knitr::kable(
digits = 3,
caption = "Estimates from the SLR model of `score` on `age`.",
booktabs = TRUE
)
int.model <- lm(score ~ age * gender, data = evals_multiple)
get_regression_table(int.model)
mlr.model <- lm(score ~ age + bty_avg, data = evals)
model.comp.values.slr.age <- glance(lm(score ~ age, data = evals))
model.comp.values.slr.age <- glance(lm(score ~ age, data = evals))
model.comp.values.slr.age
model.comp.values.slr.age <- glance(lm(score ~ age, data = evals))
model.comp.values.slr.age
model.comp.values.slr.bty_avg
model.comp.values.slr.bty_avg <- glance(lm(score ~ bty_avg, data = evals))
model.comp.values.slr.bty_avg
Models <- c('SLR(age)','SLR(bty_avg)','MLR')
bind_rows(model.comp.values.slr.age, model.comp.values.slr.bty_avg,
model.comp.values.mlr, .id = "Model") %>%
select(Model, adj.r.squared, AIC, BIC) %>%
mutate(Model = Models) %>%
kable(
digits = 2,
caption = "Model comparison values for different models.",
)
Models <- c('SLR(age)','SLR(bty_avg)','MLR')
bind_rows(model.comp.values.slr.age, model.comp.values.slr.bty_avg,
model.comp.values.mlr, .id = "Model") %>%
select(Model, adj.r.squared, AIC, BIC) %>%
mutate(Model = Models) %>%
kable(
digits = 2,
caption = "Model comparison values for different models.",
)
bind_rows(model.comp.values.slr.age, model.comp.values.slr.bty_avg,
model.comp.values.mlr, .id = "Model") %>%
select(Model, adj.r.squared, AIC, BIC) %>%
mutate(Model = Models) %>%
kable(
digits = 2,
caption = "Model comparison values for different models.",
)
bind_rows(model.comp.values.slr.age, model.comp.values.slr.bty_avg,
model.comp.values.mlr, .id = "Model") %>%
select(Model, adj.r.squared, AIC, BIC) %>%
mutate(Model = Models) %>%
knitr::kable(
digits = 2,
caption = "Model comparison values for different models.",
)
model.comp.values.mlr
model.comp.values.slr.age
model.comp.values.mlr <- glance(lm(score ~ age + bty_avg, data = evals))
Models <- c('SLR(age)','SLR(bty_avg)','MLR')
bind_rows(model.comp.values.slr.age, model.comp.values.slr.bty_avg,
model.comp.values.mlr, .id = "Model") %>%
select(Model, adj.r.squared, AIC, BIC) %>%
mutate(Model = Models) %>%
knitr::kable(
digits = 2,
caption = "Model comparison values for different models.",
)
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Data\ for\ Further\ Tasks\ Week\ 8-20210628")
LAhomes=read.csv("LAhomes.csv")
LAhomes=read.csv("LAhomes.csv")
LAhomes
hist1 <- ggplot(LAhomes, aes(x = price)) +
geom_histogram()
hist2 <- ggplot(LAhomes, aes(x = sqft)) +
geom_histogram()
hist1log <- ggplot(LAhomes, aes(x = log(price))) +
geom_histogram()
hist2log <- ggplot(LAhomes, aes(x = log(sqft))) +
geom_histogram()
plot1 <- ggplot(LAhomes, aes(x = sqft, y = price)) +
geom_point()
plot2 <- ggplot(LAhomes, aes(x = log(sqft), y = log(price))) +
geom_point()
grid.arrange(hist1, hist2, hist1log, hist2log, plot1, plot2,
ncol = 2, nrow = 3)
grid.arrange(hist1, hist2, hist1log, hist2log, plot1, plot2,
ncol = 2, nrow = 3)
?grid.arrange
??grid.arrange
library(gridExtra)
library(gridExtra)
grid.arrange(hist1, hist2, hist1log, hist2log, plot1, plot2,
ncol = 2, nrow = 3)
#b. Fit the simple linear model with log(price) as the response and log(sqft) as the predictor.
#Display the fitted model on a scatterplot of the data and construct a bootstrap confidence
#interval (using the percentiles of the bootstrap distribution) for the slope parameter in the
#model and interpret its point and interval estimates.
LAhomes=mutate(LAhomes,log.price=log(price),log.sqft=log(sqft))
slr.model1=lm(log(price)~log(sqft),data=LAhome)
slr.model1 <- lm(log(price) ~ log(sqft), data = LAhomes)
ggplot(LAhomes,aes(x=log(sqft),y=log(price)))+
geom_point()+
geom_smooth(method=lm, se = FALSE)
coeff <- slr.model1 %>% coef()
coeff <- slr.model1 %>% coef()
percentile_beta_ci <- LAhomes %>%
specify(log.price ~ log.sqft) %>%
generate(reps = 1000, type = "bootstrap") %>%
calculate(stat = "slope") %>%
get_ci(level = 0.95, type = "percentile")
percentile_beta_ci
#c. Repeat the analysis in part b. but with the log of the number of bathrooms (bath) as the
#single explanatory variable.
LAhomes <- mutate(LAhomes,log.bath=log(bath))
slr.model2 <- lm(log(price) ~ log(bath), data = LAhomes)
ggplot(LAhomes,aes(x=log(bath),y=log(price)))+
geom_point()+
geom_smooth(method=lm, se = FALSE)
coeff2 <- slr.model2 %>% coef()
percentile_beta_ci2 <- LAhomes %>%
specify(log.price ~ log.bath) %>%
generate(reps = 1000, type = "bootstrap") %>%
calculate(stat = "slope") %>%
get_ci(level = 0.95, type = "percentile")
mlr.model <- lm(log(price) ~ log(sqft)+log(bath), data = LAhomes)
coeff3 <- mlr.model %>% coef()
coeff3
mlr.model.est <- get_regression_table(mlr.model)
str(mlr.model.est)
percentile_beta1_ci <- c(mlr.model.est$lower_ci[2],mlr.model.est$upper_ci[2])
percentile_beta2_ci <- c(mlr.model.est$lower_ci[3],mlr.model.est$upper_ci[3])
percentile_beta1_ci
percentile_beta1_ci
percentile_beta2_ci
#e. Using the objective measures for model comparisons, which of the models in parts b., c. and
#d. would you favour? Is this consistent with your conclusions in part d.?
model.comp.values.slr.model1 <- glance(slr.model1)
model.comp.values.slr.model2 <- glance(slr.model2)
model.comp.values.mlr.model <- glance(mlr.model)
Models <- c("SLR(log(sqft))","SLR(log(bath))","MLR")
bind_rows(model.comp.values.slr.model1, model.comp.values.slr.model2,
model.comp.values.mlr.model,.id="Model") %>%
select(Model,adj.r.squared,AIC,BIC) %>%
mutate(Model=Models) %>%
kable(
digits = 2,
caption = "Model comparison values for different models",
)
bind_rows(model.comp.values.slr.model1, model.comp.values.slr.model2,
model.comp.values.mlr.model,.id="Model") %>%
select(Model,adj.r.squared,AIC,BIC) %>%
mutate(Model=Models) %>%
knitr::kable(
digits = 2,
caption = "Model comparison values for different models",
)
library(GGally)
library(GGally)
#glimpse(restNYC)
restNYC$East <- as.factor(restNYC$East) # East needs to be a factor
ggpairs(restNYC[,4:8], aes(colour = East, alpha = 0.4)) # Including the `East` factor
ggpairs(restNYC[,4:7], aes(alpha = 0.4)) # Without the `East` factor
restNYC=read.csv("restNYC.csv")
library(GGally)
#glimpse(restNYC)
restNYC$East <- as.factor(restNYC$East) # East needs to be a factor
ggpairs(restNYC[,4:8], aes(colour = East, alpha = 0.4)) # Including the `East` factor
ggpairs(restNYC[,4:7], aes(alpha = 0.4)) # Without the `East` factor
ggpairs(restNYC[,4:7], aes(alpha = 0.4)) # Without the `East` factor
ggpairs(restNYC[,4:8], aes(colour = East, alpha = 0.4)) # Including the `East` factor
slr.Service <- lm(Price ~ Service, data=restNYC)
ggplot(restNYC,aes(x=Service,y=Price))+
geom_point()+
geom_smooth(method=lm, se = FALSE)
coeff.Service <- slr.Service %>% coef()
percentile_beta_Service_ci <- restNYC %>%
specify(Price ~ Service) %>%
generate(reps = 1000, type = "bootstrap") %>%
calculate(stat = "slope") %>%
get_ci(level = 0.95, type = "se", point_estimate=coeff.Service[2])
mlr.Service.Food.Decor <- lm(Price ~ Service + Food + Decor, data=restNYC)
get_regression_table(mlr.Service.Food.Decor) %>%
kable(
digits = 2,
caption = "Parameter estimates for MLR model of Price on Service, Food, and Decor",
)
mlr.Service.Food.Decor <- lm(Price ~ Service + Food + Decor, data=restNYC)
get_regression_table(mlr.Service.Food.Decor) %>%
knitr::kable(
digits = 2,
caption = "Parameter estimates for MLR model of Price on Service, Food, and Decor",
)
