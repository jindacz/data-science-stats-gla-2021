prop.r=F,prop.t=F,prop.chisq = F)
#We can use the table command to find the number of applicants that get rejected.
table(train[train$Credit_amount>=11000,"Creditability"])
# Replace the four question marks with the correct variables and data set
ggplot(train, aes(x=Credit_amount, y=Purpose, fill=Creditability)) +
geom_density_ridges(alpha=0.5) +
theme_ridges()
first_tree=rpart(Creditability~Account_balance+Age,data=train,
,method="class")
#To change the splitting criterion, the following command can be used. You could try it and compare with
#the previous tree. For this example, it turns out that there is no difference at all on the resulting tree.
second_tree=rpart(Creditability~Account_balance+Age, data=train, method="class",
parms = list(split='information'))
#Example 4
#We could change the number of observations that must exist in a node in order for a split to be attempted
#by writing
third_tree <- rpart(Creditability~Account_balance+Age, data=train, method="class",
minsplit=100)
#If we want a tree to have at most three consecutive splits, we would set maxdepth to the value 3.
complex_tree_maxdepth <- rpart(Creditability~Account_Balance+Age+Purpose+Credit_amount,
data = train, method = "class", maxdepth=3)
#If we want a tree to have at most three consecutive splits, we would set maxdepth to the value 3.
complex_tree_maxdepth <- rpart(Creditability~Account_balance+Age+Purpose+Credit_amount,
data = train, method = "class", maxdepth=3)
#By default, the complexity parameter is 0.01. To grow a larger tree, we will need to decrease its value.
first_tree_grown <- rpart(Creditability~Account_balance+Age, data=train,
method="class", cp=0.004)
second_tree_fully_grown <- rpart(Creditability~Age+Length_of_cur_employment
+Purpose, data=train, method="class",
parms=list(split='information'),
cp=-1, minsplit=2, minbucket=1)
complex_tree_maxdepth_penalty <- rpart(Creditability~Account_balance+Age
+Purpose+Credit_amount,
data=train, method="class",
maxdepth=3, parms=list(loss=lossmatrix))
newtest
newtest$CreditProb
newtest$CreditProb <- predict(second_tree_pruned, newdata=newtest, type="prob")
colnames(test)[c(2,3,5:9,11:16)] <- c("Account_balance","Duration_of_credit",
"Credit_amount","Value_savings_stocks","Length_of_cur_employment",
"Installment_rate_in_percent","Sex_and_marital_status","Age","Concurrent_credits",
"Apartment_type","Credits_at_bank","Dependents","Foreign_worker")
newtest <- test[,c("Creditability","Age","Length_of_cur_employment","Purpose")]
newtest$CreditProb <- predict(second_tree_pruned, newdata=newtest, type="prob")
newtest$CreditClass <- predict(second_tree_pruned, newdata=newtest, type="class")
newtest$CreditClass <- predict(second_tree_pruned, newdata=newtest, type="class")
newtest$CreditProb[1:3,]
newtest <- test[,c("Creditability","Age","Length_of_cur_employment","Purpose")]
newtest
second_tree_pruned
rpart.plot(second_tree_pruned)
#mining_week_3
iris
head(train.set)
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/mining/Datasets\ for\ week\ 4-20210602")
#Let’s have a look at the training data first
library(plyr)
library(skimr)
library(knitr)
train=read.csv("German_train.csv")
train=train[,c(-1,-5,-13,-14,-19,-21)]
View(train)
train$Account.Balance <- as.factor(train$Account.Balance)
train$Sex...Marital.Status <- as.factor(train$Sex...Marital.Status)
train$Type.of.apartment <- as.factor(train$Type.of.apartment)
train$Purpose <- as.factor(train$Purpose)
train$Length.of.current.employment <- as.factor(train$Length.of.current.employment)
train$Creditability <- as.factor(train$Creditability)
train$Creditability=revalue(train$Creditability,c("0"="No_Credit",
"1"="Credit"))
colnames(train)[c(2,3,5:9,11:16)] <- c("Account_balance","Duration_of_credit",
"Credit_amount","Value_savings_stocks","Length_of_cur_employment",
"Installment_rate_in_percent","Sex_and_marital_status","Age","Concurrent_credits",
"Apartment_type","Credits_at_bank","Dependents","Foreign_worker")
?skim_with
my_skim <- skim_with(base=sfl(n=length),factor=sfl(ordered=NULL),
numeric=sfl(p0=NULL,p100=NULL,hist = NULL))
knit_print(my_skim(train))
#We should try to perform some exploratory analysis before we do anything else. Here, we will check:
#• the relationship between creditability and account balance using the crossTable functions
#• and a histogram of the credit that the applicants ask for.
#(In reality we should do way more exploratory analysis)
install.packages("gmodels")
library(gmodels)
CrossTable(train$Creditability,train$Account_balance,digits=2,
prop.r=F,prop.t=F,prop.chisq = F)
#We can use the table command to find the number of applicants that get rejected.
table(train[train$Credit_amount>=11000,"Creditability"])
#Task 2 Ridgeline plots can be useful for visualising different distributions (and/or visualising changes in distributions over time or space). Can you use these plots to see the distributions of the amount of credit that
#the applicants are asking for, for each of the four different purposes of credit, and colour it according to
#their applications being accepted or rejected.
install.packages("ggridges");library(ggridges)
install.packages("gmodels")
library(ggplot2)
View(train)
# Replace the four question marks with the correct variables and data set
ggplot(train, aes(x=Credit_amount, y=Purpose, fill=Creditability)) +
geom_density_ridges(alpha=0.5) +
theme_ridges()
#example_2
#In this case, we want to classify the variable Creditability using two features (age and account balance),
#so our call to rpart should look like
install.packages("rpart.plot")
library(rpart);library(rpart.plot)
first_tree=rpart(Creditability~Account_balance+Age,data=train,
,method="class")
#use method="class" for factors
#i.e for a classification tree rather than a regression tree
rpart.plot(first_tree,type=2,extra=4)
first_tree
#To change the splitting criterion, the following command can be used. You could try it and compare with
#the previous tree. For this example, it turns out that there is no difference at all on the resulting tree.
second_tree=rpart(Creditability~Account_balance+Age, data=train, method="class",
parms = list(split='information'))
rpart.plot(second_tree,type=2,extra=4)
#Example 4
#We could change the number of observations that must exist in a node in order for a split to be attempted
#by writing
third_tree <- rpart(Creditability~Account_balance+Age, data=train, method="class",
minsplit=100)
rpart.plot(third_tree,type=2,extra=4)
#If we want a tree to have at most three consecutive splits, we would set maxdepth to the value 3.
complex_tree_maxdepth <- rpart(Creditability~Account_balance+Age+Purpose+Credit_amount,
data = train, method = "class", maxdepth=3)
rpart.plot(complex_tree_maxdepth,type=2,extra=4)
#By default, the complexity parameter is 0.01. To grow a larger tree, we will need to decrease its value.
first_tree_grown <- rpart(Creditability~Account_balance+Age, data=train,
method="class", cp=0.004)
rpart.plot(first_tree_grown,type=2,extra=4)
#Let’s start with a tree that is fully grown (notice the negative value on the complexity parameter argument)
set.seed(1)
second_tree_fully_grown <- rpart(Creditability~Age+Length_of_cur_employment
+Purpose, data=train, method="class",
parms=list(split='information'),
cp=-1, minsplit=2, minbucket=1)
rpart.plot(second_tree_fully_grown)
#To see the cross validation results use the printcp() function
printcp(second_tree_fully_grown)
#Alternatively, we could prune the tree using the cp of the tree that is within one standard deviation
#of the tree with the smallest xerror; in the case that there are multiple trees with the same xerror, we
#will choose the smaller one (since that tree would predict as well as the other one but it would also
#have fewer branches, thus avoiding overfitting). In this example, the smallest xerror is 0.99301 with the
#corresponding standard deviation of 0.070512. So, we want the tree with xerror less than 1.063522 (=
#0.99301+0.070512). Since only tree 3 has xerror smaller than this value, we would want to prune our tree
#with a cp slightly greater than the value 0.006993.
second_tree_pruned=prune(second_tree_fully_grown,cp=0.007)
rpart.plot(second_tree_pruned)
#If you want to challenge yourself, you can use R commands to double check that the result for the training
#data error rate you just computed is correct.
class.pred=predict(second_tree_fully_grown,type="class")
mean(class.pred!=train$Creditability)
#Example 6.
#If the bank wants to identify a high percentage of incorrectly labelled approved applications without worrying too much about investigating incorrectly labelled accepted applications they can set the loss matrix
#to penalise applications incorrectly labeled as approved four times as applications incorrectly labeled as
#rejected.
lossmatrix=matrix(c(0,4,1,0),byrow=T,nrow=2)
lossmatrix
complex_tree_maxdepth_penalty <- rpart(Creditability~Account_balance+Age
+Purpose+Credit_amount,
data=train, method="class",
maxdepth=3, parms=list(loss=lossmatrix))
rpart.plot(complex_tree_maxdepth_penalty,type=2,extra=4)
#Example 7.
#For the pruned tree built in Example 5, we can see that the most important variable is Purpose and the
#least important value is Length_of_cur_employment.
second_tree_pruned$variable.importance
#We can do this using the predict function, with either type="prob" or type="class" where the first
#will return the probabilities of each class in the predicted terminal node for the case and the second will
#simply give the predicted class based on the class with maximum probability in the predicted terminal
#node of the case:
test <- read.csv("German_test.csv")
test$Account.Balance <- as.factor(test$Account.Balance)
test$Sex...Marital.Status <- as.factor(test$Sex...Marital.Status)
test$Type.of.apartment <- as.factor(test$Type.of.apartment)
test$Purpose <- as.factor(test$Purpose)
test$Length.of.current.employment <- as.factor(test$Length.of.current.employment)
test$Creditability <- as.factor(test$Creditability)
test$Creditability <- revalue(test$Creditability, c("0"="No_Credit","1"="Credit"))
test <- test[,c(-1,-5,-13,-14,-19,-21)]
colnames(test)[c(2,3,5:9,11:16)] <- c("Account_balance","Duration_of_credit",
"Credit_amount","Value_savings_stocks","Length_of_cur_employment",
"Installment_rate_in_percent","Sex_and_marital_status","Age","Concurrent_credits",
"Apartment_type","Credits_at_bank","Dependents","Foreign_worker")
newtest <- test[,c("Creditability","Age","Length_of_cur_employment","Purpose")]
newtest$CreditProb <- predict(second_tree_pruned, newdata=newtest, type="prob")
newtest$CreditClass <- predict(second_tree_pruned, newdata=newtest, type="class")
newtest$CreditProb[1:3,]
newtest$CreditProb[1:3,]
newtest <- test[,c("Creditability","Age","Length_of_cur_employment","Purpose")]
newtest$CreditProb <- predict(second_tree_pruned, newdata=newtest, type="prob")
newtest$CreditClass <- predict(second_tree_pruned, newdata=newtest, type="class")
newtest$CreditProb[1:3,]
newtest
newtest$CreditClass[1:3]
newtest$CreditProb[1:3,]
#For the pruned version of the tree (second_tree_pruned in Example 7), compute:
#• the sensitivity and the specificity,
#• the false discovery rate and
#• the test accuracy,
#where positive is having the application approved and negative is having the application rejected.
cross.class.tab=table(newtest$Creditability,newtest$CreditClass)
cross.class.tab
newtest$Creditability
newtest$CreditClass
#For the pruned version of the tree (second_tree_pruned in Example 7), compute:
#• the sensitivity and the specificity,
#• the false discovery rate and
#• the test accuracy,
#where positive is having the application approved and negative is having the application rejected.
cross.class.tab=table(newtest$Creditability,newtest$CreditClass)
cross.class.tab
#divide by the sum of rows
cross.class.rates=prop.table(cross.class.tab,1)
cross.class.rates
#sensitivity
cross.class.rates[2,2]
cross.class.tab<-table(newtest$Creditability,newtest$CreditClass)
cross.class.tab
#divide by the sum of columns
cross.class.rates<-prop.table(cross.class.tab,2)
#False discovery rate
cross.class.rates[1,2]
library(purrr); set.seed(1)
data <- seq(from = 1, to = 10)
library(purrr)
data <- seq(from = 1, to = 10)
# sample without replacement
rerun(3,sample(data,replace=F))
# sample with replacement
rerun(3, sample(data, replace = TRUE))
set.seed(1)
data=rnorm(50,5,3)
head(data)
#We want to estimate the standard error of the median. How are we going to do that if we only have one sample?
#We can create more (bootstrap) samples and find the median at each one and then compute the standard error.
resamples <- lapply(1:1000, function(i) sample(data, replace = TRUE))
resamples[1]
resamples
r.median <- sapply(resamples, median)
head(r.median)
sd(r.median)
hist(r.median, main="Histogram of median", cex.main=0.6, cex.lab=0.6)
## Load the package and data
library(faraway)
library(MASS)
library(nycflights13)
glimpse(Alaska)
library(gapminder)
glimpse(Alaska)
?glimpse
library(tidyverse)
glimpse(Alaska)
dim(Alaska)
library(nycflights13)
dim(Alaska)
glimpse(c(1,1))
library(ggplot2)
library(nycflights13)
library(ggplot2)
library(nycflights13)
print("Well done!  You've loaded the libraries")
help("package=nycflights13")
head(flights,n=3)
dim(flights)
glmpse(flights)
glimpse(flights)
library(tidyverse)
# packages containing interesting data
library(nycflights13)
library(fivethirtyeight)
print("Well done!  You've loaded the libraries")
dim(flights) #Returns the dimensions of a dataframe
head(flights) #Returns the first 6 rows of the object
glimpse(flights) #Lists the variables in an object with their first few values
#help(package = "packagename")
help(package = "nycflights13")
glimpse(airports)
?airports
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das")
library(readr)
dem_score=read.csv("dem_score.csv")
dem_score
library(readxl)
dem_score <- read_excel("dem_score.xlsx")
View(dem_score)
library(readr)
life_exp_scores <- read_csv("https://moderndive.com/data/le_mess.csv")
head(life_esp_scores)
guat_dem <- dem_score %>%  #does not work
filter(country == "Guatemala")
#guat_dem <- subset(dem_score, dem_score$country == "Guatemala")
?filter
guat_dem
#软件包中的gather()功能tidyr可以为我们完成此任务。第一个参数gather()，
#就如同用ggplot2()，是data我们指定我们想整齐的数据帧的说法。接下来的两个参数
#gather()是key和value，它们指定了我们想要调用的新列，这些新列将我们的宽数据转换
#为长格式。最后，我们使用列出了我们不希望在此整理过程中不包括的变量的规范-
guat_tidy=gather(data=guat_dem,
key=year,
value=democracy_score,
-country)
guat_tidy
#filter observation using filter
#该filter函数允许您指定有关数据集中变量值的条件，然后仅选择与该条件匹配的那些行。
#我们从返回flights数据nycflights13包中的数据框开始，仅关注从纽约市到俄勒冈州波特兰
#的航班。dest俄勒冈州波特兰的代码（或机场代码）为"PDX"。运行以下命令并查看生成的电子表格
#以确保此处仅选择前往波特兰的航班：
portland_flights <- flights %>%
filter(dest == "PDX")
head(portland_flights[,seq(-6,-12)])
#filter observation using filter
#该filter函数允许您指定有关数据集中变量值的条件，然后仅选择与该条件匹配的那些行。
#我们从返回flights数据nycflights13包中的数据框开始，仅关注从纽约市到俄勒冈州波特兰
#的航班。dest俄勒冈州波特兰的代码（或机场代码）为"PDX"。运行以下命令并查看生成的电子表格
#以确保此处仅选择前往波特兰的航班：
portland_flights <- flights %>%
filter(dest == "PDX")
head(portland_flights[,seq(-6,-12)])
View(flights)
###
#使用mutate创建新变量/更改旧变量
flights=flights%>%
mutate(gain=dep_delay-arr_delay)
flights
View(flights)
flights %>%
inner_join(planes, by = "tailnum") %>%
select(carrier, seats, distance) %>%
group_by(carrier) %>%
summarize(TS = sum(seats, na.rm = TRUE)) %>%
arrange(TS)
flights
flights %>%
inner_join(planes, by = "tailnum") %>%
select(carrier, seats, distance) %>%
group_by(carrier) %>%
summarize(TS = sum(seats, na.rm = TRUE)) %>%
arrange(TS)
flights %>%
group_by(origin, month) %>%
summarize(count = n())
flights %>%
group_by(origin) %>%
group_by(month) %>%
summarize(count = n())
flights %>%
group_by(month) %>%
group_by(origin) %>%
summarize(count = n())
flights %>%
group_by(month, origin) %>%
summarize(count = n())
?html_name
url <- "https://rvest.tidyverse.org/articles/starwars.html"
html <- read_html(url)
url <- "https://rvest.tidyverse.org/articles/starwars.html"
html <- read_html(url)
library(rvest)
url <- "https://rvest.tidyverse.org/articles/starwars.html"
html <- read_html(url)
html %>%
html_element("div") %>%
html_children() %>%
html_name()
html %>%
html_element("div") %>%
html_children()
html %>%
html_element("div") %>%
html_children() %>%
html_name()
html %>%
html_element("div") %>%
html_children()
html %>%
html_element("div") %>%
html_children() %>%
html_name()
hist(r.median, main="Histogram of median", cex.main=0.6, cex.lab=0.6)
library(randomForest)
install.packages("randomForest")
set.seed(11)
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
get_regression_table(model)%>%
dplyr::select(term,estimate)%>% #Note that it seems necessary to include dplyr:: here!!
kable(caption='\\label{tab:reg} Estimates of the parameters from the fitted linear
regression model.')%>%
kable_styling(latex_options="HOLD_position")
get_regression_table(model)%>%
dplyr::select(term,estimate)%>% #Note that it seems necessary to include dplyr:: here!!
kable(caption='\\label{tab:reg} Estimates of the parameters from the fitted linear
regression model.')%>%
kable_styling(latex_options="HOLD_position")
get_regression_table(model)%>%
dplyr::select(term,estimate)%>% #Note that it seems necessary to include dplyr:: here!!
kable(caption='\\label{tab:reg} Estimates of the parameters from the fitted linear
regression model.')%>%
kable_styling(latex_options="HOLD_position")
1
3+5
model=lm(Hwt~Sex,data=cats)
model
get_regression_table(model)
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604/Glasgow_Edinburgh_SIMD2020.csv ")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
Glasgow_Ed_SIMD2020
Glasgow_Ed_SIMD2020
View(Glasgow_Ed_SIMD2020)
Glasgow_tidy=gather(data=Glasgow_Ed_SIMD2020,
key=Type_of_Rank,
value=Rank,
SIMD_rank:Housing_Rank)
library(tidyverse)
library(moderndive)
library(skimr)
library(kableExtra)
library(gridExtra)
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
View(Glasgow_Ed_SIMD2020)
Glasgow_tidy
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
Glasgow_tidy=gather(data=Glasgow_Ed_SIMD2020,
key=Type_of_Rank,
value=Rank,
SIMD_rank:Housing_Rank)
Glasgow_Ed_SIMD2020_tidy1 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
SIMD_Rank:Housing_Rank)
Glasgow_Ed_SIMD2020_tidy1
View(Glasgow_Ed_SIMD2020_tidy1)
View(Glasgow_Ed_SIMD2020)
Glasgow_Ed_SIMD2020_tidy1
Glasgow_Ed_SIMD2020_tidy1
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
View(Glasgow_Ed_SIMD2020_tidy1)
Glasgow_Ed_SIMD2020_tidy1 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
SIMD_Rank:Housing_Rank)
Glasgow_Ed_SIMD2020_tidy1
View(Glasgow_Ed_SIMD2020)
Glasgow_Ed_SIMD2020_tidy1$Type_of_Rank <-
str_replace(Glasgow_Ed_SIMD2020_tidy1$Type_of_Rank, "_Rank", "")
Glasgow_Ed_SIMD2020_tidy1 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
-(Data_Zone:Working_Age_population)))
Glasgow_Ed_SIMD2020_tidy1 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
-(Data_Zone:Working_Age_population))
library(tidyverse)
library(moderndive)
library(skimr)
library(kableExtra)
library(gridExtra)
setwd("/Users/kurisuuu/Documents/glasgow_stats_2021/semester\ 2/das/Practice\ Class\ Test\ Files-20210604")
Glasgow_Ed_SIMD2020 <- read_csv("Glasgow_Edinburgh_SIMD2020.csv")
Glasgow_Ed_SIMD2020_tidy2 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
-(Data_Zone:Working_Age_population))
Glasgow_Ed_SIMD2020=Glasgow_Ed_SIMD2020_tidy2%>%
filter(Type_of_Rank=="SIMD")%>%
mutate(Perc_Wroking==100*Working_Age_population/Total_population)
Gla_Ed_SIMD2020 <- Glasgow_Ed_SIMD2020_tidy2 %>%
filter(Type_of_Rank == "SIMD") %>% #2 MARKS
mutate(Perc_Working = 100 * Working_Age_population/Total_population)
Gla_Ed_SIMD2020 <- Glasgow_Ed_SIMD2020_tidy2 %>%
filter(Type_of_Rank == "SIMD") %>% #2 MARKS
mutate(Perc_Working = 100 * Working_Age_population/Total_population)
ggplot(Gla_Ed_SIMD2020)+
geom_point(mapping=aes(x=Perc_Working,y=Rank,group=Council_area,
color=Council_area))+
labs(x="Employment Rate of Working Age Population",y="SIMD2020 Rank")
ggplot(Gla_Ed_SIMD2020)+
geom_point(mapping=aes(x=Perc_Working,y=Rank,group=Council_area,
color=Council_area))+
labs(x="Employment Rate of Working Age Population",y="SIMD2020 Rank")
ggplot(Gla_Ed_SIMD2020)+
geom_point(mapping=aes(x=Perc_Working,y=Rank,group=Council_area,color=Council_area))+ #3 MARKS
labs(x="Employment Rate of Working Age Population",y="SIMD2020 Rank")
Gla_Ed_SIMD2020
1
Gla_Ed_SIMD2020
Gla_Ed_SIMD2020 <- Glasgow_Ed_SIMD2020_tidy2 %>%
filter(Type_of_Rank == "SIMD") %>% #2 MARKS
mutate(Perc_Working = 100 * Working_Age_population/Total_population)
Gla_Ed_SIMD2020
Glasgow_Ed_SIMD2020_tidy2 <- gather(data = Glasgow_Ed_SIMD2020,
key = Type_of_Rank,
value = Rank,
-(Data_Zone:Working_Age_population))
Glasgow_Ed_SIMD2020_tidy2$Type_of_Rank <-
str_replace(Glasgow_Ed_SIMD2020_tidy2$Type_of_Rank, "_Rank", "")
Gla_Ed_SIMD2020 <- Glasgow_Ed_SIMD2020_tidy2 %>%
filter(Type_of_Rank == "SIMD") %>% #2 MARKS
mutate(Perc_Working = 100 * Working_Age_population/Total_population)
Gla_Ed_SIMD2020 <- Glasgow_Ed_SIMD2020_tidy2 %>%
filter(Type_of_Rank == "SIMD") %>% #2 MARKS
mutate(Perc_Working = 100 *Working_Age_population/Total_population)
Gla_Ed_SIMD2020
ggplot(Gla_Ed_SIMD2020)+
geom_point(mapping=aes(x=Perc_Working,y=Rank,group=Council_area,color=Council_area))+ #3 MARKS
labs(x="Employment Rate of Working Age Population",y="SIMD2020 Rank")
